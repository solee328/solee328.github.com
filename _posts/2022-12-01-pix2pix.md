---
layout: post
title: Pix2Pix(1) - 논문 분석
# subtitle:
categories: gan
tags: [pix2pix, 생성 모델, 논문 분석]
# sidebar: []
use_math: true
---

## 소개
Pair 데이터를 사용한 생성 모델인 Pix2Pix

논문 모든 내용을 번역하지 않고 중요한 부분들을 요약해 번역 -> 의역 존재


## Abstract
image-to-image 변환 문제에 대한 범용 솔루션으로 conditional adversarial networks(이후 조건부 GAN으로 대체 사용하겠습니다)를 사용하며 입력 이미지에서 출력 이미지로의 매핑을 학습하기 위한 loss 함수를 사용합니다. label map, edge map에서 개체를 합성 / 재구성하고 이미지를 colorizing에 효과적이라는 것을 보여줍니다.

## 1. Introduction
이미지 처리, 컴퓨터 그래픽스, 컴퓨터 비전의 많은 과제들은 입력 이미지를 출력 이미지로 변환하는 것에 대해 질문을 던집니다. 장면(이미지)는 RGB image, gradient field, edge map, semantic label map 등 다양하게 렌더링될 수 있는데 자동 언어 번역과 유사한 자동 image-to-image 변환을 충분한 학습 데이터가 주어진다면 한 장면의 표현을 다른 장면으로 변환하는 작업으로 정의할 수 있습니다. 과거의 이런 과제들은 각각 별도의 특수 목적의 시스템으로 처리되었지만 본 논문에서 우리의 목표는 이러한 모든 문제에 대한 공통된 프레임워크를 개발하는 것입니다.<br>
convolutional neural nets(CNNs)로 다양한 이미지 예측 문제를 해결하는 방향으로 연구들이 진행되고 있고 CNNs는 loss 함수를 최소화하는 방향으로 학습합니다. 하지만 효과적인 loss 함수를 만드는 것은 아직 많은 수작업이 필요합니다. 단순한 접근 방식으로 CNN에게 예측(predicted)과 실제(ground truth)의 유클리디안 거리를 최소화하는 것은 흐릿한 결과를 생성하는 경향이 있습니다. 유클리디안 거리를 최소화하는 것은 결과의 모든 값을 평균화하는 것이기 때문이 흐릿한 결과를 유도하기 때문입니다.<br>
'현실과 구별할 수 없는 출력을 만든다'와 같이 고수준의 목표를 명시하는 대신 목표를 달성하기 위한 적절한 loss 함수를 학습할 수 있다면 매우 바람직합니다. 다행히 최근 제안된 Generative Adversarial Networks(GANs)에 의해 수행할 수 있으며 GANs는 출력이 실제인지 가짜인지 구별하는 판별 모델 loss를 학습하는 동시에 이 loss를 최소화하기 위한 생성 모델 또한 학습합니다. 흐릿한 이미지는 명백히 가짜로 보이기 때문에 GANs는 흐릿한 이미지를 가짜로 판별하고 생성 모델은 더 선명한 이미지를 생성하게 될 것입니다.<br>
본 논문에서 우리는 GANs의 조건 설정을 탐구합니다. GAN이 데이터 생성 모델을 학습하는 것처럼 조건부 GANs(cGAN)은 조건부 생성 모델을 학습합니다. cGAN은 조건부 입력 이미지에 따라 출력 이미지를 생성하는 image-to-image 변환에 적합합니다.<br>
조건부 GANs가 다양한 과제들에 대해 합리적인 결과를 생성한다는 것을 입증합니다. 코드는  https://github.com/phillipi/pix2pix 에서 확인할 수 있습니다.

## 2. Related work
Structed losses for image modeling, Conditional GANs와 관련된 논문들이 열거되어 있습니다.
Structed losses for image modeling에서 image-to-image 변환 문제는 주로 per-pixel classification이나 regression으로 수식화하고 문제를 해결했으나 조건부 GAN은 loss를 학습한다는 점에서 기존 수식 모델과는 다르고 출력과 정답의 오차가 있는 구조에 대해 loss를 이용해 불이익을 줄 수 있다는 점이 나와있습니다.<br>
Conditional GANs에서는 조건부 Gan이 inpainting, future state prediction, super resolution과 같은 여러 image-to-image 분야에서 인상적인 결과를 달성한 분야들이 있었습니다. 각 방법들은 목적에 맞는 다른 term(예시: L2 regression)들로 loss를 조정했는데 본 논문의 연구는 특정 목적이 없는 것이 특징입니다. 또한 이전 논문들과는 생성 모델과 판별 모델의 구조에 차이가 있는데 생성 모델은 'U-Net'을 사용하고 판별 모델은 'PatchGAN'을 사용하는 것이 특징입니다.

## 3. Method
$$
그림 넣기, Figure 2
$$

GANs는 랜덤 노이즈 벡터 $z$를 출력 이미지 $y$로 매핑하는 매핑 $G : z \rightarrow y$ 을 수행하는 모델입니다. 대조적으로 조건부 GANs는 조건에 해당하는 이미지 $x$와 랜덤 노이즈 벡터 $z$를 출력 이미지 $y$로 매핑하는 매핑 $G : \{ x, z \} \rightarrow y$ 을 학습해 수행합니다.

### 3.1. Objective
조건부 GAN의 목적 함수는 아래의 수식과 같습니다.

$$
\mathcal{L} _{cGAN}(G, D) = \mathbb{E} _{x,y} [logD(x, y)] + \mathbb{E} _{x, z}[log(1-D(x, G(x, z)))] \tag{1}
$$

$G$는 목적 함수를 최소화하려고 하며 목적 함수를 최대화하려는 $D$에 대항합니다. 이를 다시 정리하면 $G^* = arg \min_G \max_D \mathcal{L} _{cGAN}(G, D)$ 로 표현할 수 있습니다.

[전통적 목적 함수를 섞으면 도움이 되며 L2보단 L1이 좋았음]
<a href=https://arxiv.org/abs/1604.07379 target='_blank'>'Context Encoders: Feature Learning by Inpainting'</a>과 같은 연구는 전통적인 loss와 GAN의 목적 함수를 섞는 것이 도움이 된다는 것을 발견했습니다. 판별 모델이 생성 모델이 생성한 가짜 이미지와 진짜 이미지를 구별해야 한다는 목적은 언제나 같지만 생성 모델의 경우 판별 모델을 속일 뿐만 아니라 실제 이미지와 최대한 유사해야 하기 때문에 L2 loss가 도움이 됩니다. 저자들은 L1이 흐릿함을 덜 유발한다는 점에서 L1 distance가 L2 distance 보다 사용하기 좋다는 것 또한 연구했다 합니다.

$$
\mathcal{L}_{L1}(G) = \mathbb{E} _{x, y, z}[\| y-G(x, z) \|_1]
\tag{3}
$$

위의 두 식을 합쳐 본 논문에서 사용하는 최종 목적 함수는 다음와 같습니다.

$$
G^* = arg \min\limits_{G} \max\limits_{D} \mathcal{L} _{cGAN}(G, D) + \lambda \mathcal{L} _{L1}(G)}
\tag{4}
$$

[z 입력을 주지 않고 dropout으로 해결하고자 했으나 실패]
$z$를 입력으로 같이 넣어주지 않는다해도 $x$를 $y$로 매핑하는 것을 모델이 학습할 수 있지만 확정된 출력 값을 생성하며 delta function 의 분포만 포현할 수 있습니다. delta function은 --- 입니다. Mathieu --- 연구의 경우 --로 노이즈 $z$가 필요하지 않았으며 $z$를 넣어 학습해도 $z$를 무시하는 방향으로 학습했습니다. 따라서 본 연구에서는 노이즈 $z$를 $G$에 입력하지 않으며 대신 dropout을 이용했습니다. dropout으로 노이즈를 제공했지만 결과에서는 minor stochasticity만이 발견되었으며 이러한 low stochasticity는 현재 연구에서 해결되지 않는 중요한 문제 입니다.


### 3.2. Network architectures
[44]dcgan의 생성 모델과 판별 모델 구조를 채택했습니다. 생성 모델과 판별 모델 모두 convolution-BatchNorm-ReLu[29] 구조의 모듈을 사용합니다.

#### 3.2.1 Generator with skips
$$
그림 넣기, Figure 3
$$

[encoder-decoder에 skip connection을 추가한 unet 사용]
image-to-image 변환 문제는 고해상도 입력을 고해상도 출력으로 매핑해야 한다는 것입니다. 입출력 이미지의 텍스쳐 등의 질감을 달라야 하지만 기본 구조는 같도록 만들어야 한다. 이 문제에 대한 이전의 다양한 솔루션 [43, 55, 30, 64, 59]는 encoder-decoder 네트워크[26]를 사용합니다. 이 네트워크는 bottle neck 이라 불리는 레이어까지 downsample되는 레이어들을 통과합니다. 이미지 변환 문제의 경우 입력과 출력 사이에 low-level 정보들이 공유되고 이 정보들은 네트워크를 통해 전달되는 것이 바람직합니다. 하지만 bottle neck으로 이런 정보들이 손실되는 것을 피하기 위해 'U-Net'의 모양을 따라 skip connection을 추가합니다. 우리는 각 레이어 $i$와 레이어 $n - i$ 사이에 skip connection을 추가하며 여기서 $n$은 전체 레이어의 수이다.

-> 추가설명(low level informatino / unet skip connection 의미(bottle neck이 왜 정보가 손실되는가 skip connection으로 channel 변경은 어찌 되는가))
여기서 low-level 정보는 이미지의 low level feature를 말하며 이미지의 edge, corner, color 등이 해당됩니다.

#### 3.2.2 Markovian discriminator (PatchGAN)
[patch gan 사용 이유]
L2, L1 loss가 이미지 생성 문제에 대해 흐릿함(blur)을 생성한다는 것은 잘 알려져 있습니다[34]. L2, L1 loss는 high frequency를 잘 포착하지 못하지만 low frequency를 정확하게 포착합니다. 따라서 low frequency 정확도를 높이기 위해 L1 term을 사용하며 이 L1이 high frequency 정확도가 낮다는 것을 알기에 판별 모델을 high frequency 구조만 모델링하도록 제한할 동기를 부여한다. 로컬 이미지 패치의 구조에 대해 집중하는 것으로 고주파를 모델링할 수 있기에 패치 규모로만 수행되는 판별 모델 구조를 설계합니다. 이 판별 모델은 N x N 패치가 실제인지 가짜인지 분류하며 모든 응답의 평균을 $D$의 출력으로 내보냅니다.

4.4에서 우리는

### 3.3. Optimization and inference

## 4. Experiments
Data requirements and speed

### 4.1. Evaluation metrics

AMT perceptual studies

"FCN score"

### 4.2. Analysis of the objective function

colorfulness

### 4.3. Analysis of the generator architecture

### 4.4. From PixelGANs to PatchGANs to ImageGANs
Fully-convolutional translation


### 4.5. Perceptual validation


### 4.6. Semantic segmentation

### 4.7. Community-driven Research


## 5. Conclusion
